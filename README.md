# Project 3 Generative Audio

Your Name, yourcontact@ucsd.edu

(Your teammate's contact info, if appropriate)

## Abstract

My proposal is to use a gpt2 text generation system trained on Malcolm gladwell’s books, and then make them speak in some way. I want to then read snippets of this text with a voice synthesizer hopefully trained on malcolm’s voice from his many audiobooks narrarated by himself. As one of the most popular loving nonfiction artists, I think he is seen as a contemporary source of wisdom. I was thinking that I could make a box that spits out quotes of “wisdom” to see if it makes any sort of profound revelation. I could make this by laser cutting acrylic at work for the container and using a raspberry pi I have at home. I'm really interested in vocal synthesis, but i'm getting hun up on what the data used to train these systems looks like. I'm curious how much front end work i'd need to do to get something resembling the human voice from a collection of audiobooks alone.



## Model/Data

Briefly describe the files that are included with your repository:
- trained models
- training data (or link to training data)

## Code

Your code for generating your project:
- Python: generative_code.py
- Jupyter notebooks: generative_code.ipynb

## Results

Documentation of your results in an appropriate format, both links to files and a brief description of their contents:
- `.wav` files or `.mp4`
- `.midi` files
- musical scores
- ... some other form

## Technical Notes

Any implementation details or notes we need to repeat your work. 
- Does this code require other pip packages, software, etc?
- Does it run on some other (non-datahub) platform? (CoLab, etc.)

## Reference

References to any papers, techniques, repositories you used:
- Papers
- Repositories
- Blog posts
